发射概率只和当前状态有关，是较简单的模型。
当遇到语料库中没有的word就返回平均概率
概率和为1，到后面乘积越来越小，然后变成0，之后就都是0了，就全部都是S
准确率0.65
------------------------------
先将语句用逗号分开，所有逗号都是S，这样可以减小长度，避免因长度过大而产生的概率消失。
同时，Pi_dic[key]和A['S'][key]应该是差不多的，key='S' or 'B'的概率和等于1，因为都不可能为'I' or 'E'，所以把逗号后面的那个字当做一个句子的开头来预测应该也差不多
准确率0.75
------------------------------
当遇到语料库中没有的word返回当前状态发射概率的最小值
准确率0.78
------------------------------
HMM2的发射概率和当前状态以及下一个状态有关，建模能力应该更强，但是……
准确率：0.76
------------------------------
HMM的viterbi_sum把乘法改成加法以解决梯度消失
准确率：0.39
原因应该在于概率没有化成对数，相对大小会发生变化
------------------------------
HMM.py加了对数处理
准确率只有0.5
------------------------------
HMM2.py加了对数处理，准确率有上升0.1左右，
dataset1有0.78，dataset2有0.82
1的train有23444行，2才只有15235行，为啥准确率还更高？
------------------------------
CRF.py，训练一个epoch
相对路径问题，是相对于顶层的路径，所以参数文件的路径最好作为一个参数传进来
准确率：0.82
------------------------------
epoch = 5
dataset1
准确率：0.85
dataset2
准确率：0.92
------------------------------
dataset1&2 epoch = 5
训练集准确率：0.9887350250938813
准确率：0.907223308403717
------------------------------
HMM两个数据集合在一起
准确率：0.81
------------------------------
epoch = 10(在原来5次的基础上迭代,62min)
dataset2:0.92，过拟合，后面5次基本就没涨
------------------------------
只留下标识两个字的模板
dataset2-epoch5-template1
train accuracy= 0.9974434018244174 valid accuracy= 0.9053367217280813 time: 35.26829883654912 min
------------------------------
unigram留下一个字的模板，bigram留下两个字的模板
dataset2-epoch5-template2
train accuracy= 0.8706735459473595 valid accuracy= 0.7992376111817027 time: 28.23314762910207 min
------------------------------
都只留下一个字的模板
dataset2-epoch5-template3
train accuracy= 0.8706735459473595 valid accuracy= 0.7992376111817027 time: 27.660934015115103 min
-------------------------------
只留下006之后的模板
dataset2-epoch5-template4
train accuracy= 0.9968801858612678 valid accuracy= 0.9040660736975857 time: 29.19031368494034 min
-------------------------------
只留下5,7,8,9
dataset2-epoch5-template5
train accuracy= 0.9969003007170946 valid accuracy= 0.8856416772554002 time: 28.41412031253179 min
U6很重要
-------------------------------
只留下5,6,8,9
dataset2-epoch5-template6
train accuracy= 0.9967145735482941 valid accuracy= 0.9047013977128335 time: 28.55057655175527 min
-------------------------------
在train_a_sentence方法里发现两处代码错误
1.更新bigram的时候用的是unigram的模板
2.if else赋值的优先级搞错了，忘记加括号了
更改之后dataset2-epoch5的结果：
train accuracy= 0.9940104664299818 valid accuracy= 0.9135959339263025 time: 59.55414261817932 min